---
title: "Preguntas y respuestas de mi charla en la BilboStack 2024"
lang: es
date: 2024-01-31T16:26:27+01:00
last_modified_at: 2024-02-04T08:26:27+01:00
redirect_from:
  - /blog/talks/preguntas-y-respuestas-bilbostack-2024/
categories:
  - blog
  - talks
tags:
  - talks
  - bilbostack24
  - spanish
---

Cuando en la pasada y maravillosa [BilboStack](https://bilbostack.com/){:target="_blank"}{:rel="noopener noreferrer"} finalic√© [mi charla sobre Continuous Deployment](/blog/talks/slides-and-resources-talk-bilbostack-2024) (no me cansar√© de repetir que como excusa para hablar de "lo importante"), me hicieron saber que no hab√≠a ninguna pregunta üò±
 En mi experiencia, cuando eso pasa, es que el nivel de turra ha sido astron√≥mico y el mensaje no ha llegado de ninguna manera üòÖ

Por suerte, parece ser que la explicaci√≥n era menos dram√°tica: hubo alg√∫n problema con la aplicaci√≥n que recog√≠a las preguntas (¬øfaltar√≠a alg√∫n test? üòú). La organizaci√≥n ha tenido el detallazo de envi√°rmelas _a posteriori_, as√≠ que intentar√© contestarlas en este post.

**Aclaraci√≥n importante**: me falta much√≠simo contexto en casi todas las preguntas; necesitar√≠a entender mejor much√≠simas cosas antes de dar una respuesta "razonable". Lo har√© expl√≠cito en las respuestas de algunas pero lo inferir√© en otras üôè

---------------------------

1. **¬øPuedes explicar c√≥mo conseguir la ISO 27001/SOC2 trabajando en continuos delivery?**
- Resumen: realmente no ü§£ Pero puedo compartir algunas cosillas que tal vez ayude en algo...
- Algo que comentaba el otro d√≠a hablando con otra persona sobre este tema es que tendemos a dar por hecho demasiadas cosas. Lo primero que siempre debemos hacer es ENTENDER en profundidad las necesidades a satisfacer. Creo que hay mucho "tel√©fono escacharrao" e inferimos que se necesitan muchas cosas que en realidad son una posible soluci√≥n (e.g. que haya una PR) en lugar de la necesidad de base a resolver (e.g. que m√°s de una persona haya revisado algo).
- Dicho esto: tengo claro que el auditor que te toque puede influir much√≠simo.
- A mucho m√°s alto nivel, Clarity public√≥ un post al respecto: ["ISO27001 and SOC2 Type II from Greenfield to Success"](https://medium.com/clarityai-engineering/iso27001-and-soc2-type-ii-from-greenfield-to-success-24ca99decb26)
- En mi equipo hac√≠amos de hecho "Continuous Deployment" y en nuestro caso era suficiente con seguir los siguientes requisitos:
  * Cada commit inclu√≠a el **issue de Jira** que lo originaba: se generaba una traza inequ√≠voca con la necesidad de la que surg√≠a ese c√≥digo.
  * Puesto que trabaj√°bamos en pairing o ensemble por defecto, en cada commit inclu√≠amos a todas las personas involucradas usando el **["Co-authored-by" de Git](https://docs.github.com/es/pull-requests/committing-changes-to-your-project/creating-and-editing-commits/creating-a-commit-with-multiple-authors)**      
        - Para reducir la fricci√≥n, todos ten√≠amos un **template del [git message](https://gist.github.com/lisawolderiksen/a7b99d94c92c6671181611be1641c733)** con el resto de compa√±eras del equipo, no ten√≠amos que estar escribi√©ndolo conitnuamente.
        - Hasta donde s√©, y simplificando mucho, una de las cosas que se requiere es **evidencia** de que una persona diferente a quien escribi√≥ el c√≥digo, lo ha revisado. Esta pr√°ctica satisfac√≠a esa necesidad.  
  * Si el cambio a realizar era "muy trivial" (lo cual siempre es abstracto, pero ten√≠amos un documento defini√©ndolo), se permit√≠a que no hubiera un revisor (e.g. cambio en documentaci√≥n). En estos casos, era suficiente con incluir en el mensaje del commit cierta palabra clave (en nuestro caso concreto, `[trivial-small-change]`)
- Para la gente que trabajaba con ramas y PRs, la persona que validaba la PR deb√≠a ser diferente a la persona que la hab√≠a abierto.
- Si necesitas m√°s detalle, probablemente [Edu Ferro](https://twitter.com/eferro) pueda contarte m√°s cosas üôè

1. **¬øQu√© opinas de los code freeze? ¬øTienen sentido en determinados casos? Por ejemplo, una empresa grande con equipos distribuidos en distintas zonas horarias**
- Preguntas que me surgen:
  - ¬øHablamos de equipos distribuidos o de sistemas distribuidos? ¬øO de ambas cosas?
  - Cuando hablamos de equipos distribuidos, ¬øa nivel individual o de equipo? ¬øEst√°n todos los miembros de un mismo equipo en zonas horarias muy diferentes? ¬øO la dispersi√≥n era a nivel de equipo? (es decir, miembros de un mismo equipo en zona horaria similar, pero cada equipo en zonas horarias muy diferentes)
- Si bien creo que todo puede tener sentido en alg√∫n contexto, en general los "code freeze" (sobre todo si ocurren con relativa frecuencia) son un mal s√≠ntoma. El mero hecho de ser una empresa grande con equipos distribuidos en distintas zonas horarias no implica que deban existir esos "code freeze". Cada equipo deber√≠a tener el ownership e2e de un "value stream" (ver los ["stream-aligned teams" de Team Topologies](https://martinfowler.com/bliki/TeamTopologies.html)).
- Aqu√≠ entra en juego y hay que tener mucho cuidado con la [ley de Conway](https://martinfowler.com/bliki/ConwaysLaw.html) y [su reverso](https://www.agileanalytics.cloud/blog/team-topologies-the-reverse-conway-manoeuvre), c√≥mo est√°n dise√±ados los equipos, los sistemas y sus responsabilidades.
- Algo que tambi√©n puede ayudar es la existencia de ["Team APIs"](https://medium.com/agile-outside-the-box/team-apis-af2dbc1805e7).
- Seg√∫n el nivel de solapamiento horario, se pueden poner unas horas "core" para el pairing/ensemble.
- Si hablamos de personas distribuidas: una estrategia de branching tipo ["Ship, Show, Ask"](https://martinfowler.com/articles/ship-show-ask.html) puede ser interesante.
- Si de lo que hablamos es de un sistema distribuido y no s√≥lo equipos distribuidos (que no es lo mismo), entonces es fundamental hacer muy buen ["Contract Testing"](https://martinfowler.com/bliki/ContractTest.html): cada sistema/servicio deber√≠a poder ser testeado funcionalmente de forma "aislada" sin depender del resto de servicios. Esto es independiente de tener alg√∫n tipo de tests end-to-end adicionales (lo cual en sistemas complejos distribuidos se complica bastante).

1. **¬°Gracias por la charla! ¬øCu√°l ser√≠a en tu opinion una buena estrategia de ramas? Actualmente al tener baby-commits y al mergear con la rama principal optamos por squash and merge, que crea un nuevo c√≥digo de commit y se pierde el rastro de los antiguos commits entrando en un infierno de commits a la hora de revisar PRs. Nos suelen pedir intentar hacer un solo commit por desarrollo y luego mergeo (not fast foward) y yo consigo eso con git -ammend**
- Mi primera respuesta: "depende" üòú
- Mi segunda respuesta: la estrategia de ramas que, en general, mejor permite tener feedback r√°pido y un aporte de valor continuo y sostenible es "Trunk-Based Development" con una √∫nica rama por defecto (acompa√±ado, como comentaba en la charla, de pair/ensemble programming, TDD, una pipeline segura, repetible y potente, micro-commits, etc.)
- Personalmente priorizo el flow continuo y llevar cuanto antes el commit a Producci√≥n, que un hist√≥rico "impoluto" de commits. Lo que s√≠ es siempre importante es que los commits sean descriptivos y cuenten claramente "el porqu√©" ante todo ("el qu√©" est√° impl√≠cito en el commit).
- En la l√≠nea de lo que comentas, la buena gente de [Codely](https://codely.com/) grab√≥ hace un par de a√±os un v√≠deo con sus opiniones al respecto, creo que te podr√≠a interesar en caso de que no puedas trabajar con una rama √∫nica, te lo recomiendo: ["Git Merge vs Rebase vs Squash ¬øQu√© estrategia debemos elegir?"](https://www.youtube.com/watch?v=HlmZLXMOpEM)

1. **¬øVentajas y desventajas de tener los test en un git hook?**
- Aclaraci√≥n: todo lo que se meta en Git hooks debe ser "r√°pido". Qu√© significa "r√°pido" depende de la sensibilidad de cada persona o equipo, pero en mi experiencia, toda ejecuci√≥n que supere los 5 segundos empieza a "doler" (los "push" pueden tardar algo m√°s porque los solemos ejecutar con menos frecuencia, pero no mucho m√°s). En cualquier caso, y en mi opini√≥n, es mejor tener que esperar "un poco" en el momento del commit-push que encontrarnos con demasiadas "sorpresas" m√°s tarde (problema de "context switch"). Y por otra parte, es conveniente balancear qu√© se incluye en el pre-commit y qu√© en el pre-push (ver [ejemplos en los diagramas con ejemplos reales de la charla](./2024-01-29-slides-and-resources-talk-bilbostack-2024.md))
- _Ventajas_: tener feedback mucho m√°s r√°pido si fallan los tests (no tener que esperar a que fallen en la pipeline, cuando ya hemos cambiado el foco y estamos a medias de otra cosa). Por supuesto no incluir√≠a los tests m√°s "lentos", pero s√≠ los "r√°pidos" (en mi opini√≥n todos los unitarios deber√≠an serlo, as√≠ como algunos de integraci√≥n - qu√© considero "unitario" o "integraci√≥n" da para otro post). 
- _Inconvenientes_: el inconveniente surge si su ejecuci√≥n es "demasiado lenta"; lo que acabar√° pasando es que los saltaremos o acumularemos demasiados cambios. La soluci√≥n pasa por tener en los Git hooks √∫nicamente los tests m√°s r√°pidos o que no provoquen demasiada sensaci√≥n de ralentizaci√≥n. Paralelizar todo lo posible su ejecuci√≥n es importante para disminuir los tiempos.

1. **De primeras, muy interesante. Como pregunta ¬øno notaste que los hooks pre-commit y pre-push podian a√±adir friccion y latencia en el proceso de commit, llevando al equipo a hacer commits mas grandes para evitar hacer menos commits por pasar menos procesos?**  
Muy buena pregunta, y por desgracia no es dif√≠cil que ocurra, hay que estar muy pendiente de ello. Lo he intentado contestar en la pregunta anterior ‚òùÔ∏èüôè

1. **¬øValidaciones sincronas o PR en asincrono?**
- No s√© si entiendo esta pregunta, lo siento. ¬øQu√© quieren decir "validaciones"? ¬øHablamos de los tests? ¬øDe linters? ¬øO de la revisi√≥n de c√≥digo?
- En la l√≠nea de lo que coment√© en la charla: debemos intentar tener feedback los m√°s r√°pido y frecuente posible de todo. En la medida de lo posible, priorizar√≠a las revisiones de c√≥digo s√≠ncronas; y a√∫n mejor: hacer pairing/ensemble todo lo "posible".
- Tambi√©n recomendar√≠a echar un vistazo a la estrategia de branching ["Ship, Show, Ask"](https://martinfowler.com/articles/ship-show-ask.html),  puede ser interesante como avance hacia la reducci√≥n de tiempos de integraci√≥n.

1. **Cuando el "circulo vicioso" que has ense√±ado al principio se ha hecho tan grande, ¬øc√≥mo sales de ah√≠?**
- Uuufffff, dif√≠cil pregunta (o mejor dicho, dif√≠cil respuesta üòÖ). Lo primero necesario es tener consciencia general del problema y de su naturaleza (yo dir√≠a que esto es lo m√°s dif√≠cil). Hacerlo visible y expl√≠cito, con datos, siempre ayuda (e.g. tomar tiempos de todo lo que ocurre desde que hacemos un commit hasta que llega a Producci√≥n), ponerlo negro sobre blanco. 
- Lo siguiente importante es querer realmente invertir tiempo para resolverlo, ver claramente el beneficio que eso puede reportar (lo cual de nuevo suele ser muy dif√≠cil si no se ha experimentado antes). 
- Si se cumple todo lo anterior: ir poquito a poco. Identificar primero los "quick wins" que puedan existir (bajo coste y alto beneficio). Mejorar el testing automatizado. Ir disminuyendo todo lo posible los tiempos de nuestras ramas/PRs. Adoptar estrategias de branching que disminuya el tiempo que tardamos en integrar en la rama principal. Aumentar y mejorar la colaboraci√≥n (e.g. a trav√©s del pairing). Aprender t√©cnicas de cambios paralelos y empezar a usar "feature flags".
- Y creo que el mejor consejo: buscad y contratad a alguien con experiencia en todo lo anterior, es extramadamente dif√≠cil si no (no digo que no sea posible, pero s√≠ muy complicado).

1. **¬øComo se puede poner en valor el aporte de CI/CD y hacer perder el miedo a desarrolladorxs de desplegar pronto cosas?**  
Yo como mejor lo he visto hacer es liderando con el ejemplo (lo cual requiere experiencia haci√©ndolo), haciendo al mismo tiempo mucha pedagog√≠a al respecto (sobre el valor que aporta a todes, tanto negocio como ingenier√≠a). No creo que haya atajos ni f√≥rmulas m√°gicas... üòï Por supuesto, ese "desplegar pronto cosas" debe ir acompa√±ado de una red de seguridad potente, si no ser√° peor el remedio que la enfermedad y la gente, con raz√≥n, no querr√° hacerlo.

1. **¬øUtilizas estrategias de pairing como el ping-pong? En estos casos, ¬øno ser√≠a molesto el uso de Git Hooks?**
- En el pasado s√≠ he hecho pairing con TDD en ping-pong (dir√≠a que he hecho pairing en todas o casi todas las modalidades posibles ü§£)
- Cuando he hecho ping-pong (la persona A escribe el test, B lo pasa, refactor, B escribe el siguiente test, etc.) lo hac√≠a compartiendo el terminal (es decir, ambas personas trabaj√°bamos realmente en la misma m√°quina, usando [tmate](https://tmate.io/)). Eso implica que no hac√≠amos commit hasta que el test no estuviera en verde (y por tanto los Git hooks no eran un problema).
- Algo que no har√≠a, independientemente de los Git Hooks, es subir c√≥digo a la rama principal sin tests.
- Hay gente que usa [esta herramienta](https://github.com/remotemobprogramming/mob), podr√≠a cubrir seg√∫n qu√© casos de uso (personalmente prefiero no hacer ping-pong y ya est√°, rotamos por pomodoro y ya es suficiente).
- Sobre pairing, este post es realmente bueno: [On Pair Programming](https://martinfowler.com/articles/on-pair-programming.html)

1. **¬øTener muchos micro commits no puede ensuciar la rama main?**
- Depende de lo que se entienda por "ensuciar". Lo que siempre es importante es tener commits con buenos mensajes, describiendo muy bien "el porqu√©"; y por supuesto ning√∫n commit debe romper los tests. 
- Dicho esto, creo que es m√°s importante dar pasitos peque√±os y el feedback y flow muy continuos que una supuesta historia de commits "ideal".

1. **Generalmente lo que se pide es que la feature este completa antes de subir y no quieren ver nada hasta que no est√©, ¬øSer√≠a aplicable trunk-based?**  
- Absolutamente. Para resolver el problema que describes, que efectivamente es muy habitual, existen m√∫ltiples t√©cnicas de cambios paralelos ([inclu√≠ informaci√≥n al respecto](https://islomar.es/blog/talks/slides-and-resources-talk-bilbostack-2024/#parallel-changes)) y sobre todo el uso de [feature flags/toggles](https://martinfowler.com/articles/feature-toggles.html). 
- Esto est√° relacionado con el desacoplamiento que mencionaba durante la charla entre "Deployment" (decisi√≥n t√©cnica) y "Release" (decisi√≥n de negocio).

1. **Para usar CD con trunk-based development, a la hora de hacer commits y pushearlos, ¬øteniais algun tipo de configuracion para prevenir commit que no pasasen los tests?**  
S√≠, ten√≠amos configurados Git hooks tanto de pre-commit como de pre-push. En los [diagramas de los slides de la charla](/blog/talks/slides-and-resources-talk-bilbostack-2024) puedes ver qu√© inclu√≠amos en cada uno de ellos. Por la forma en que funcionan los Git hooks, si el pre-commit no pasa (i.e. si estado de salida es distinto de cero), no se realiza el commit (idem para el pre-push).

1. **A la pregunta que ha hecho: "Es para cambiar el Mundo, porque en mayor o menos medida cuando subimos un cambio, estos cambian la vida de algunas personas (para bien o para mal) nuestros usuarios o cliebtes, porque tienen herramientas para hacer mejor su trabajo"**  
- Entiendo que esto es la respuesta a la pregunta que lanc√©: "¬øPara qu√© desarrollamos software profesionalmente?". Me parece una perspectiva maravillosa, la verdad, me siento muy alineado con la idea que subyace a ella.
- En relaci√≥n con el matiz que mencionaba en mi respuesta y que era lo que quer√≠a resaltar, te dir√≠a: ¬øy si pudieras cambiar/mejorar el mundo de manera m√°s √≥ptima/eficiente **SIN** software, no lo har√≠as? üòâ

1. **¬øTendr√≠a sentido ejecutar varios procesos de CI en paralelo? Por ejemplo los unit tests, construir la build y los e2e tests a la vez**  
- S√≠, pero depende de cuales. Sin duda **debemos paralelizar todo lo posible**, comenzando por los propios tests (casi todas las librer√≠as de testing permiten la ejecuci√≥n en paralelo); adem√°s, as√≠ nos forzamos a escribir tests "autocontenidos", cuya entrada o salida no dependa de otros tests ni los contamine (lo cual es por defecto lo m√°s recomendable). Con los tests unitarios y de integraci√≥n no deber√≠a haber problema. Con los tests e2e/acceptance tal vez s√≠ (merece la pena diferenciar cu√°les se puden paralelizar y hacerlo).
- En los [dos ejemplos reales que inclu√≠](https://speakerdeck.com/islomar/valor-por-encima-de-codigo-el-poder-del-despliegue-continuo?slide=44), puedes ver qu√© paralelizamos y qu√© no, dir√≠a que casi todo con mucha consciencia (y siempre mejorable) üòä
- Si por ejemplo miramos la segunda pipeline, te puedo contar por qu√© no paralelizamos en concreto las tres tareas que comentas:
  - No quer√≠amos invertir tiempo en el build de la imagen de Docker (y el posterior push a un ECR) si los tests no pasaban antes.
  - Los tests unitarios son los m√°s r√°pidos, por lo que son los m√°s bloqueantes: no queremos hacer nada m√°s si eso falla (otro motivo por el que no paralelizarlos con seg√∫n qu√©). S√≠ los podemos paralelizar con otras tareas tambi√©n r√°pidas, como linters y otras validaciones est√°ticas.
  - En cuanto a los tests e2e: en nuestra taxonom√≠a de testing, esos son tests que lanzamos contra la nueva versi√≥n del sistema ya desplegado en alguna parte (staging o production), por lo que no podr√≠amos paralelizarlo tampoco con la build o tests unitarios.
  - Los tests que s√≠ paralelizamos como primer paso de la pipeline son los **unitarios** (cumplen [los principios FIRST](https://github.com/tekguard/Principles-of-Unit-Testing){:target="_blank"}{:rel="noopener noreferrer"}), **integraci√≥n** (en nuestro caso son tests para los adaptadores secundarios de [nuestra arquitectura hexagonal](https://herbertograca.com/2017/09/14/ports-adapters-architecture/){:target="_blank"}{:rel="noopener noreferrer"}) y tests de aceptaci√≥n (que son tests "desde fuera" y los lanzamos contra el sistema que incluye las actualizaciones, levantado "en local", antes de ser deplegado).

1. **Cuando haces TDD outside-in haces primero los tests desde el punto de vista del usuario pero, ¬øcontinuas con tests m√°s internos?**  
- Exactamente, √©sa es la idea. Similar a [Acceptance TDD](https://www.agilealliance.org/glossary/atdd/), [Specification by Example](https://gojko.net/books/specification-by-example/){:target="_blank"}{:rel="noopener noreferrer"} o [Behaviour-Driven Development (BDD)](https://dannorth.net/introducing-bdd/){:target="_blank"}{:rel="noopener noreferrer"} (existen matices de diferencias entre los tres, pero en los tres casos buscamos testear el comportamiento del sistema desde el punto de vista de su usuario externo)
- Decir que tal vez no siempre sea posible (yo no siempre lo consigo), pero s√≠ deber√≠a ser el primer enfoque: cuando se hace as√≠, la experiencia de desarrollo es fant√°stica (y por supuesto tambi√©n revierte en la de usuario) üòç

1. **¬øConsideras indispensable que el continous delivery llegue siempre hasta producci√≥n? ¬øNo ser√≠a suficiente con un entorno de Test que sea una replica de Producci√≥n para evitar riesgos?**  
- No debemos confundir "Continuous Delivery" y "Continuous Deployment". En la primera parte de mi charla intent√© explicar [las diferencias](https://speakerdeck.com/islomar/valor-por-encima-de-codigo-el-poder-del-despliegue-continuo?slide=16){:target="_blank"}{:rel="noopener noreferrer"}.
- Con **"Continuous Delivery"**, efectivamente la pipeline no llega a desplegar en Producci√≥n. Puede, por ejemplo, quedarse en un enterno previo (e.g. Staging). Lo importante es que una vez nuestro c√≥digo se integra en la rama principal y se ejecuta la build y tests automatizados, queda en un "estado desplegable": cuando lo deseemos, a voluntad, podr√≠amos desplegarlo a Producci√≥n (ese despliegue deber√≠a ser sencillo y repetible).
- Con **"Continuous Deployment"**, ah√≠ ya s√≠, toda la pipeline est√° completamente automatizada, incluido el paso de despliegue a Producci√≥n.
- En la primera pipeline de ejemplo que mencion√©, ten√≠amos Continuous Deployment pero s√≠ se desplegaba previamente a un entorno de Staging: tras desplegar ah√≠, se ejecutaban autom√°ticamente varios tests e2e y smoke (lo m√°s cr√≠tico) y si todo funcionaba correctamente, autom√°ticamente se desplegaba a Producci√≥n.

1. **Entendiendo que una release es un concepto de negocio y no tecnol√≥gico, ¬øpor qu√© tomar el _product delivery lead time_ es importante como m√©trica? ¬øNo es algo fuera del control de tecnolog√≠a?**  
- Buena pregunta. Mi respuesta: porque es fundamental verlo como un "todo". Desde "ingenier√≠a/tecnolog√≠a" tenemos que entender que la tecnolog√≠a es un medio para un fin. 
- Para m√≠ es una de las claves de la evoluci√≥n hacia "product engineering": entender que TODOS somos producto y negocio, que lo que hacemos debe responder a necesidades de usuarios.
- En realidad desde "ingener√≠a" podemos y debemos influir mucho m√°s de lo que creemos en el "product delivery lead time". Muy a menudo he visto c√≥mo la visi√≥n de los _product managers_ cambia (para bien) cuando los desarrolladores ponemos sobre la mesa formas m√°s sencillas de empezar a satisfacer la necesidad del usuario.
- Evidentemente, es necesaria la cultura adecuada en la empresa para que lo anterior ocurra y no nos encontremos con reinos de taifas y compartimentos estancos donde diferenciemos por completo "negocio" y "tecnolog√≠a": debemos ir hacia entender que **todos somos PRODUCTO** y necesitamos colaborar de forma continua e intensa.
- Por √∫ltimo: como yo lo veo, un "product team" est√° compuesto de perfiles varios, todos con igual importancia. El "product manager/owner" debe ser un miembro m√°s del equipo, con horizontalidad respecto a los dem√°s.

1. **Al trabajar siempre en la misma rama, si se hace push al server y algo falla. Como parte de ese rollback ¬øse auto generar√≠a un commit con revert? ¬øO tendr√≠amos bloqueado la rama principal?**  
- Lo primero: hagamos en cada contexto lo que mejor que podamos y sepamos, que ya es mucho üòÑ
- En el [segundo ejemplo del mundo real](https://speakerdeck.com/islomar/valor-por-encima-de-codigo-el-poder-del-despliegue-continuo?slide=45){:target="_blank"}{:rel="noopener noreferrer"} que inclu√≠ en la charla, era un rollback muy r√°pido del despliegue, por lo que no se generaba ning√∫n commit. Por dar m√°s detalles t√©cnicos, hac√≠amos el [rollback con helm](https://helm.sh/docs/helm/helm_rollback/){:target="_blank"}{:rel="noopener noreferrer"} (que era lo que tambi√©n us√°bamos para el despliegue).
- Cuando eso ocurr√≠a, recib√≠amos un mensaje en el canal de Slack de equipo que ten√≠amos para cuestiones importantes (e.g. cualquier fallo en la pipeline). 
- El rollback autom√°tico en Producci√≥n nos daba la tranquilidad de saber que se quedaba en un estado estable, que segu√≠a funcionando lo anterior.
- En cuanto acab√°bamos el pomodoro que estaba en curso (trabajamos principalmente en _ensemble_), prioriz√°bamos inmediatamente ver qu√© hab√≠a fallado y lo resolv√≠amos. No hab√≠a ning√∫n "bloqueo" de la rama principal porque trabaj√°bamos en _ensemble_. Pero si no fuera as√≠, como coment√© en la charla arreglar una pipeline rota debe ser **PRIORITARIO**, por lo que no es que se quede bloqueada, sino que hay que arreglarla _ipso facto_, y adem√°s todos a una en el equipo, da igual qui√©n hizo el commit que lo rompi√≥ (creo que el cambio de mentalidad es importante, y el trabajar de forma aislada y muy individualista no ayuda).
- Trabajando en rama √∫nica con lead time de minutos, no ten√≠amos necesidad del concepto de "hot fix": tras el rollback autom√°tico, en cuanto pod√≠amos lo arregl√°blamos (pocos minutos) y comite√°bamos el arreglo que fuera (con un test autom√°tico inclu√≠do para evitar que se repitiera, de ser posible) y p'arriba üòâ
- Parte de la filosof√≠a aqu√≠ es que cuando hay un incidente en Producci√≥n, lo primero y m√°s importante es que Producci√≥n deje de fallar cuanto antes: puede ser porque volvemos a la versi√≥n anterior o porque comiteamos muy r√°pidamente una soluci√≥n.
- A lo largo de 2 a√±os, son muy pocas las ocasiones en las que ese rollback nos ocurri√≥ (ten√≠amos una red de seguridad previa bastante potente). No debemos acostumbrarnos a que est√© ocurriendo cada dos por tres, ser√≠a s√≠ntoma de que tenemos que invertir en mejorar la red de seguridad previa.

1. **¬°Gracias por la charla crack! Me encanta tu punto sobre la disciplina y sobre todo el cuello de botella enfocado en el conocimiento! Tengo una duda, este mundo ha ido evolucionando con t√©rminos como CI/CD y otros como DevOps, DevSecOps. ¬øQu√© opinas sobre esto? ¬øQui√©n deber√≠a tener esta responsabilidad, una persona, un equipo? Me encantar√≠a saber tu punto de vista**  
- ¬°Gracias! Pues [opino de que](https://www.youtube.com/watch?v=GYtzu_G4A4M) con DevOps se ha llegado a una situaci√≥n de ["inversi√≥n sem√°ntica"](https://martinfowler.com/bliki/SemanticDiffusion.html): ha acabado significando exactamente lo contrario de lo que se buscaba. Se buscaba mejorar la colaboraci√≥n y derribar silos de conocimiento, bloqueos y pasos de patata caliente, pero en general ha acabado con "equipos DevOps" (en realidad un renombrado del "equipo de sistemas") que siguen manteniendo el silo, las dependencias bloqueantes, etc. _</rant>_
- [DevOps](https://martinfowler.com/bliki/DevOpsCulture.html) es una cultura, no un equipo. Lo cual no es incompatible con tener, por ejemplo, [equipo(s) de plataforma o enablers que faciliten la vida a los equipos "stream-aligned"](https://martinfowler.com/bliki/TeamTopologies.html) con diversas herramientas y servicios _self-service_. Pero los equipos, digamos "de producto externo", no deben tener dependencias bloqueantes de esos equipos. 
- Y lo mismo aplicar√≠a a DevSecOps, todo lo posible deber√≠a estar integrado en la pipeline de despliegue/delivery, probablemente apoy√°ndonos en servicios/herramientas de otros equipos.

1. **¬øCrees que el approach trunk/CI es v√°lido para resoluci√≥n de deuda t√©cnica o sustaining como incremento de versiones de frameworks o librer√≠as? ¬øO es algo exclusivo de delivery de producto?**  
- Totalmente, creo que TBD/CI puede aplicarse a m√∫ltiples contextos. 
- De hecho creo que la mejor manera de abordar la **[deuda t√©cnica](https://martinfowler.com/bliki/TechnicalDebt.html){:target="_blank"}{:rel="noopener noreferrer"}** (que por cierto, tendr√≠amos que estar seguros de que hablamos de lo mismo üòÑ) es poco a poco. Hacer "sprints de deuda t√©cnica" suele ser s√≠ntoma de falta de "slack/holgura" en el equipo (entre otras cosas).
- En cuanto a la **actualizaci√≥n de frameworks/librer√≠as**: aqu√≠ ya te dir√≠a que "depende". 
  - Para actualizaciones de librer√≠as, te dir√≠a que s√≠ (en mi equipo ten√≠amos un [renovatebot](https://github.com/renovatebot/renovate){:target="_blank"}{:rel="noopener noreferrer"} actualizando autom√°ticamente a diario todas las librer√≠as y desplegando al final igualmente la pipeline). Pero de nuevo, lo que repito todo el tiempo: necesitas una red de seguridad potente, sobre todo muy buenos tests automatizados.
  - En cuanto a actualizaciones de frameworks: depende de las implicaciones del cambio. Normalmente s√≠, pero cuando son versiones _major_ no es improbable que el impacto sea suficientemente grande como para requerir hacerlo en una rama que viva m√°s de 24 horas y poder cambiar y probar ah√≠ todo tranquilamente.

1. **¬øTienes alguna sugerencia o t√©cnica para ejecutar E2E tests en producci√≥n? ¬øTr√°fico sint√©tico, mirroring de tr√°fico, etc.?**  
Interesante pregunta üòÑ La respuesta: "depende del contexto" (sorry, not sorry). Por si te aporta, puedo contarte dos casu√≠sticas muy diferentes que me he encontrado (entre otras muchas):
- **En [Clarity AI](https://clarity.ai/){:target="_blank"}{:rel="noopener noreferrer"}**:
  - Ver la [segunda pipeline de ejemplos de la vida real](https://speakerdeck.com/islomar/valor-por-encima-de-codigo-el-poder-del-despliegue-continuo?slide=45){:target="_blank"}{:rel="noopener noreferrer"} que compart√≠. 
  - Ah√≠ ten√≠amos varios tests e2e (los que imitan a un usuario real): algunos en [Cypress](https://www.cypress.io/){:target="_blank"}{:rel="noopener noreferrer"} (el servicio principal era una [app en Slack (con un _slashcommand_)](https://api.slack.com/interactivity/slash-commands){:target="_blank"}{:rel="noopener noreferrer"}, as√≠ que estos tests acced√≠an realmente a Slack desde un navegador y ejecutaban varios comandos) y algunos en Python puro y duro (peticiones a algunos endpoints HTTP que tambi√©n public√°bamos).
  - Los servicios/aplicaciones ah√≠ desplegadas eran todas para uso interno de trabajadoras en Clarity (300 empleados en su momento), principlamente Ingenier√≠a.
  - Por todo lo anterior, en nuestro caso espec√≠fico la escalabilidad no era un problema: no ten√≠amos cientos ni miles ni millones de usuarios concurrentes. As√≠ que no necesit√°bamos tests de carga ni de estr√©s, y los tests e2e que ten√≠amos no necesitaban nada especial.
- **En [Form3](https://form3.tech/){:target="_blank"}{:rel="noopener noreferrer"}**: 
  - Aqu√≠ ya la cosa cambia: durante varios meses estuve en el (micro)equipo de escalabilidad, cuya principal responsabilidad era detectar (y a veces corregir) cuellos de botella en la escalabilidad de nuestro (no simple) sistema distribuido.
  - Decir que el producto de Form3 era (o es) un [API HTTP](https://www.api-docs.form3.tech/){:target="_blank"}{:rel="noopener noreferrer"} en fintech. Manej√°bamos muuuuucha pasta diaria y era bastante cr√≠tico (no mor√≠a gente, pero poca broma con la panoja ü§£)
  - Algo muy interesante es que trabaj√°bamos mano a mano con la gente de Ventas para generar tr√°fico simulado conforme a la predicci√≥n "real" de nuevos usuarios (e.g. si se hab√≠a firmado X contratos para cierta fecha, que implicar√≠a N clientes/usuarios nuevos).
  - Los tests e2e de carga y de estr√©s los hac√≠amos con [k6.io](https://k6.io/){:target="_blank"}{:rel="noopener noreferrer"} (de hecho Form3 acab√≥ sacando una [soluci√≥n open-source llamada 'f1'](https://github.com/form3tech-oss/f1){:target="_blank"}{:rel="noopener noreferrer"} que lo simplificaba a partir del trabajo que hicimos en mi equipo, es muy interesante, recomiendo echarle un vistazo). Cre√°bamos una distribuci√≥n de peticiones horaria diaria similar a la que sol√≠amos tener, con distribuciones Gaussianas, pero con los vol√∫menes estimados.
  - Es algo que, la verdad, no hab√≠a visto hacer antes ni lo he vuelto a ver ü§Ø

1. **¬øC√≥mo se puede balancear bater√≠as de test enormes que hacen que las pipelines tarden, con la rapidez que se necesita en trunk based?**  
- Por aclararlo, en Trunk-Based Development (TBD) o CI esa "rapidez" tampoco es tanta en mi opini√≥n: al menos mergear una vez al d√≠a en la rama principal. Yo dir√≠a que cuanta mayor frecuencia, mejor: por ejemplo, cada 2 horas m√°ximo, mejor que cada 24 horas; y si puedes trabajar con rama √∫nica por defecto y estar haci√©ndolo cada pocos minutos, miel sobre hojuelas (en mi experiencia, la diferencia es abismal, pero la vida es dura y hagamos lo que podamos...).
- Esas "bater√≠as de test enormes" que mencionas, ¬øde qu√© hablamos exactamente? ¬øPor qu√© es tan enorme? ¬øEs un gran monolito no modularizado? ¬øEs porque se tienen "demasiados" tests lentos?
- Como menciono m√°s arriba: debemos paralelizar todo lo que podamos. La mayor√≠a de nuestros tests (sean del tipo que sean, incluso de integraci√≥n y e2e) deber√≠an ser paralelizables (por defecto, siempre con excepciones, deber√≠an iniciar lo que necesiten de forma aut√≥noma y dejarlo como estaba antes).
- Con una correcta modularizaci√≥n, tal vez se podr√≠an lanzar los tests que nos den suficiente confianza para el despliegue (solo disparar los afectados, tirar de "contract testing", s√≥lo los e2e/funcionales/acceptance m√°s cr√≠ticos, etc.).
- Y por √∫ltimo: es recomendable tener muchos m√°s tests r√°pidos que lentos.

1. **Tengo sentimientos encontrados con los hooks de prepush y precommit, ya que he visto que en ocasiones han llevado a  devs hacer commits mas grandes de lo que debian de ser por no pasar los procesos de linting, tests, etc. varias veces. Te queria preguntar tu opini√≥n sobre eso. Si los has vivido o no, o si los has vivido, como habeis llegado a encauzar la situacion.** [Pregunta recibida por [Twitter](https://twitter.com/_ebikandi/status/1751521282494026052), gracias Eneko üôè]  
- Lo primero: me faltar√≠a entender por qu√© no pasan los procesos de linting, tests, etc. varias veces. ¬øEs porque hay tests flakies o alg√∫n tipo de validaci√≥n no completamente determinista? ¬øO es porque los desarrolladores "cometen errores"?
- No me he encontrado la situaci√≥n que planteas, pero porque hay varias cuestiones a las que siempre marco mucha prioridad con los Git hooks:
  - Tienen que ser **MUY r√°pidos**. Si no, dar√° pereza ejecutarlos o esperar√°s a tener muchos cambios para hacerlo.
  - Tienen que ser deterministas: no debe variar el resultado si no var√≠a la "entrada" (tests, linters, lo que sea).
  - Normalmente hacemos TDD, as√≠ que si alg√∫n test falla nos solemos enterar antes, no despu√©s (**acortar el feedback loop**).
  - Tenemos linters y formatters configurados en el propio IDE, exactamente igual que en el Git hook. Eso nos permite tener normalmente feedback a√∫n m√°s r√°pido y apenas encontrarnos sorpresas cuando se ejecutan los Git hooks.
  Y... b√°sicamente eso es todo lo que se me ocurre üòÖ Como te digo: tendr√≠a que vivir "in situ" la situaci√≥n para entender bien d√≥nde est√° exactamente la fricci√≥n üòäüôè

1. **La posibilidad de hacer Continuous Deployment ¬øno va muy ligado a la criticidad de los posibles errores de la aplicaci√≥n? Es decir, no es lo mismo introducir un bug en, por ejemplo, una plataforma para escuchar m√∫sica que en una app de transacciones econ√≥micas o que maneje datos muy sensibles.**  
- En mi opini√≥n, no üòä La motivaci√≥n principal para "Continuous X" (Integration/Delivery/Deployment), como mencionaba en la charla (perd√≥n por la autoreferencia) es **APRENDER r√°pido** (para poder adaptarnos y reorientarnos r√°pido y poder aportar valor r√°pido). Queremos tener feedback lo m√°s r√°pido posible sobre el **QU√â** (necesidades de usuario/cliente/negocio) y sobre el **C√ìMO** (sistemas/tecnolog√≠a/organizaci√≥n). Y eso, por normal general, lo queremos siempre, de hecho se me antoja que en el ejemplo que comentas (y en mi experiencia), probablemente m√°s en la aplicaci√≥n de m√∫sica que en la financiera.
- Tal y como yo lo veo, el razonamiento es el inverso: es para habilitar ese aprendizaje continuo, esos _feedback loops_ r√°pidos, por lo que necesitamos entre otras cosas una muy buena red de seguridad que conllevar√° menos errores de la aplicaci√≥n. Reducir los bugs no es un fin en s√≠ mismo, es un medio para otras cuestiones (mejorar la experiencia de usuario, el aporte de valor, el aprendizaje continuo, etc.)
- En otras palabras: en la falsa dicotom√≠a de "calidad vs. velocidad", en realidad s√≥lo con buena calidad (interna) podremos conseguir la velocidad. Es un tema ya muy tratado e incluso "probado", por ejemplo en el [Accelerate](https://itrevolution.com/product/accelerate/). Hay muchos posts interesantes al respecto, por ejemplo [este de Adam Tornhill](https://codescene.com/blog/code-quality-debunking-the-speed-vs-vs-quality-myth-with-empirical-data) o [este otro](https://nelis.boucke.be/post/trunk-based-development/).

1. **Parece que intentamos reinventar la rueda pero siempre acabamos volviendo a los conceptos de Eliyahu Goldratt. ¬øEn qu√© casos consideras que NO deber√≠amos aplicar todos estos principios? O por el contrario, ¬ølos consideras universales para cualquier espacio de problema?**  
- Uuffff... una pregunta dif√≠cil. Resumen: no, no creo que sea algo universal para cualquier espacio de problema. Por ejemplo: si tienes un CRUD puro y duro, donde adem√°s "sabes" que no se va a evolucionar apenas (algo que casi nunca me he encontrado, pero venga, imaginemos), entonces no lo aplicar√≠a. No hay incertidumbre (o eso creemos), no hay gran cosa que aprender. Pero m√°s importante a√∫n: es que en ese contexto a d√≠a de hoy **ni siquiera desarrollar√≠a software**, ya hay muchas herramientas NoCode para resolver ese tipo de casu√≠sticas (e.g. con baja l√≥gica dominio de negocio).
- Si me pusiera "coach" üòú, hablar√≠a del [framework Cynefin](https://en.wikipedia.org/wiki/Cynefin_framework) y que en el dominio "claro" est√° "t√≥ el pescao vend√≠o".
- Dicho todo esto: creo que es un contexto que, estad√≠sticamente (al menos en mi [evidencia anecd√≥tica experimentada y observada](https://en.wikipedia.org/wiki/Anecdotal_evidence)) es infinitesimal, no suele ser el contexto en el m√°s frecuentemente solemos movernos y por el que nos pagan.

1. **Cuando por el contexto de las iniciativas, por ejemplo, cambios muy complejos, no se puede mergear diariamente, ¬øno se puede considerar integraci√≥n continua?**  
- Lo primero: necesitar√≠a entender mucho mejor ese contexto que mencionas.
- Aqu√≠ voy a hacer "challenge": en la mayor√≠a de los casos en los que una persona o equipo me ha indicado que su contexto era "especial" o "demasiado complejo" y por tanto no pod√≠a hacer X o Y, cuando he ido rascando, preguntando, entendiendo, he o hemos visto que los problemas de base eran otros y en realidad s√≠ se pod√≠a hacer (o al menos empezar a andar el camino). No digo que sea tu caso, porque me falta mucha informaci√≥n, pero s√≠ digo que casi siempre se puede.
- De forma muy espor√°dica todo vale, somos humanos y es lo que hay (y de hecho hay situaciones puntuales donde no queda otra). Pero si √©sa es la situaci√≥n del d√≠a a d√≠a, si realmente no pod√©is mergear diariamente a una rama principal para vuestro trabajo habitual, me cuesta pensar que no sea un problema de conocimiento, principios y pr√°cticas (es decir, que no sea un problema autogenerado). Probablemente sea "complejidad accidental" y no "complejidad esencial" (ver el m√≠tico ["No silver bullet", de Fred Brooks](http://www.cs.unc.edu/techreports/86-020.pdf)).
- En cualquier caso: si no vas a merger al menos diariamente, no creo que podamos hablar de "continuidad" (y no pasa nada, no es una cuesti√≥n de "purismo ling√º√≠stico", sino del valor de la pr√°ctica).
- Aqu√≠ recomendar√≠a trabajar con alguien con experiencia en [t√©cnicas de cambios paralelos](https://islomar.es/blog/talks/slides-and-resources-talk-bilbostack-2024/#parallel-changes), [feature flags](https://martinfowler.com/articles/feature-toggles.html), [contract testing](https://martinfowler.com/bliki/ContractTest.html), aprender a dar pasos mucho m√°s peque√±os, etc.

1. **¬øComo ser√≠a el proceso de desplegar funcionalidades del front que dependen de cambios del back con TBD?**  
- Tirando de clich√©: me alegro de que me hagas esta pregunta ü§£. De hecho hubo una persona durante el _networking_ que me plante√≥ el mismo caso (tal vez fuera la misma).
- _Disclaimer_: es m√°s que recomendable que todo un **_value stream_** se realice dentro de un mismo equipo. Siempre hay excepciones, pero como norma general tanto Front como Back de una funcionalidad e2e deber√≠a ser **responsabilidad del mismo equipo**.
- Por una parte, de nuevo tengo que mencionar la importancia del uso de [feature flags](https://martinfowler.com/articles/feature-toggles.html) para habilitar diversos tipos de cambios en paralelo. Por ejemplo para este caso concreto, podr√≠amos tener un **_feature flag_** tanto en Front como en Back (por defecto √∫nico para ambos), de manera que pudi√©ramos desplegar de manera continua cualquiera de las dos partes sin impacto para los usuarios, mientras se va avanzando poquito a poco o esperamos "a la otra parte". La idea es ocultar al usuario aquello que a√∫n no est√© funcionando correctamente porque a√∫n se est√° trabajando en ello.
- En este punto, me gustar√≠a compartir una experiencia concreta que me parece muy relevante para este caso: el proyecto en el que trabajamos desde [Codium](https://www.codium.team/) en un cliente y del que mostr√© una de las [pipelines de Despliegue Continuo](https://speakerdeck.com/islomar/valor-por-encima-de-codigo-el-poder-del-despliegue-continuo?slide=44) que ten√≠amos (en concreto la del backend)
  - Contexto **importante**: 
        - Formamos un equipo mixto de 3 personas de Codium y otras 3 del cliente (una de ellas como "Product Manager"). Hac√≠amos **pairing y ensemble programming por defecto**. Y aunque hab√≠a una persona m√°s especializada en Front y otra en Back, el resto rot√°bamos entre ambos mundos: apenas hab√≠a silos ni compartimentos estancos, en el equipo m√°s o menos casi todos hac√≠amos de casi todo (cada uno con sus fortalezas, claro). Tambi√©n √©ramos muy aut√≥nomos para la parte de Sistemas.
        - Hab√≠a una parte de Back (en PHP, con Symphony) y otra de Front (React con TypeScript). Desde el Back public√°bamos un API HTTP que el Front consum√≠a.
  - Al turr√≥n: usamos [OpenAPI](https://www.openapis.org/) para definir el contrato a cumplir entre Front y Back. Cuando se requer√≠a alg√∫n nuevo comportamiento (o cambio) e implicaba cambios en ambos lados, lo primero que hac√≠amos era juntarnos todo el equipo para escribir juntos el "contrato". En un fichero yaml, OpenAPI permite definir dicho contrato, e.g. la URI del endpoint, tipos de entrada, tipos de salida, c√≥digos de estado HTTP devueltos, etc.
  - Una vez ten√≠amos este contrato escrito entre todos, ya pod√≠amos si quer√≠amos abordar por separado el Front y el Back. Dependiendo del tipo de cambio, en ocasiones no hac√≠a falta ni "feature flag".
  - Para asegurarnos de que ninguna de las dos partes romp√≠a el contrato, ten√≠amos varias validaciones en Git hooks y la pipeline (en el diagrama que compart√≠ se puede ver):  
        - **Backend**: 
          - Usamos [schemathesis](https://schemathesis.readthedocs.io/en/stable/). Es una herramienta que automatiza el testing de APIs HTTP, generando din√°micamente casos de tests a partir del contrato de OpenAPI. Permite m√∫ltiples configuraciones seg√∫n el n√∫mero de tests que se desean, paralelismo, etc.
          - B√°sicamente lo us√°bamos para lanzar tests din√°micos a partir del contrato contra el API publicado por el Back.
          - Lo ejecut√°bamos en dos momentos diferentes:
            - En el Git hook de pre-push, contra un entorno local (autom√°ticamente levantado con Docker)
            - Durante la pipeline se ejecutaba por ejemplo contra el entorno de Staging, una vez desplegado ah√≠ el Back.
        - **Frontend**: 
          - Usamos [jormaechea/open-api-mocker](https://github.com/jormaechea/open-api-mocker), que es un API mocker basado en OpenAPI 3.0
          - B√°sicamente levantaba un servidor mock a partir del contrato que ten√≠amos de OpenAPI, y era quien recib√≠a las peticiones durante ciertos tipos de tests del Frontend.
        - El fichero yaml con el contrato de OpenAPI estaba tanto en el Front como en el Back: esa duplicidad no era ideal, pero s√≠ muy "barata" en su momento. En la pipeline ten√≠amos una validaci√≥n para asegurarnos de que el contrato era exactamente el mismo en ambos lados (y por supuesto nos enter√°bamos inmediatamente si eso ocurr√≠a).
 - **IMPORTANTE**: la elecci√≥n de estas herramientas fue realizada hace varios a√±os, es m√°s que probable que hoy en d√≠a existan mejores soluciones üòä  
 - Si los endpoints del Back fueran consumidos por **muchos** m√°s consumidores (valga la rebuznancia), tal vez podr√≠amos plantearnos soluciones m√°s avanzadas (y tambi√©n mucho m√°s complejas, mejor esperar a necesitarlo DE VERDAD), como [Pact](https://pact.io/).

-------------------------------------------

¬°¬°Y esto es todo!! Con esto me quito la espinita de no haber podido dar respuesta a ninguna pregunta tras mi charla üòä 

La verdad es que me he divertido mucho respondiendo, ha sido un ejercicio interesante y ya s√≥lo espero haberle aportado algo a alguien üôè